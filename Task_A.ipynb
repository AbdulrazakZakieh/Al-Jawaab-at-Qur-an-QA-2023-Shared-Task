{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lvWiWCe7Yow-"
      },
      "outputs": [],
      "source": [
        "!pip install arabic-reshaper\n",
        "!pip install pyarabic\n",
        "!pip install pytrec_eval\n",
        "!pip install --upgrade openai\n",
        "!pip install tiktoken"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mogH8d4dVU15"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import openai\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import tiktoken\n",
        "from typing import List\n",
        "import json\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YOg9YD8XSKya"
      },
      "outputs": [],
      "source": [
        "\n",
        "COMPLETIONS_MODEL = \"gpt-4\"\n",
        "# COMPLETIONS_MODEL = \"gpt-3.5-turbo\"\n",
        "EMBEDDING_MODEL = \"text-embedding-ada-002\"\n",
        "openai.api_key = 'YOUR_OPENAI_API_KEY'\n",
        "threshold = 0.8"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_SECTION_LEN = 3000\n",
        "SEPARATOR = \"\\n* \"\n",
        "ENCODING = \"cl100k_base\"  # encoding for text-embedding-ada-002\n",
        "\n",
        "encoding = tiktoken.get_encoding(ENCODING)\n",
        "separator_len = len(encoding.encode(SEPARATOR))\n",
        "\n",
        "f\"Context separator contains {separator_len} tokens\""
      ],
      "metadata": {
        "id": "LH_z-OruFh1g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fCTfQN3aM2CF"
      },
      "outputs": [],
      "source": [
        "# reading the Quranic passages\n",
        "with open('QQA23_TaskA_QPC_v1.1.tsv', 'r') as f:\n",
        "    text = f.read()\n",
        "\n",
        "paragraphs = []\n",
        "current_paragraph = \"\"\n",
        "# text = text.replace('\\n', ' ')\n",
        "sentences = text.split('\\n')\n",
        "# chunk_size = 500\n",
        "current_word_count = 0\n",
        "current_chunk = []\n",
        "output_chunks = []\n",
        "ids = []\n",
        "questions = []\n",
        "\n",
        "for sentence in sentences:\n",
        "    words = sentence.split(\"\\t\")\n",
        "    if(len(words) == 2):\n",
        "      ids.append(words[0])\n",
        "      paragraphs.append(words[1])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hZvYa3HGQQJw"
      },
      "outputs": [],
      "source": [
        "df = pd.DataFrame()\n",
        "df['id'] =ids\n",
        "df['content'] =paragraphs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xqAxzevkUFho"
      },
      "outputs": [],
      "source": [
        "def get_embedding(text: str, model: str=EMBEDDING_MODEL) :\n",
        "    result = openai.Embedding.create(\n",
        "      model=model,\n",
        "      input=text\n",
        "    )\n",
        "    return result[\"data\"][0][\"embedding\"]\n",
        "\n",
        "def compute_doc_embeddings(df: pd.DataFrame):\n",
        "    \"\"\"\n",
        "    Create an embedding for each row in the dataframe using the OpenAI Embeddings API.\n",
        "\n",
        "    Return a dictionary that maps between each embedding vector and the index of the row that it corresponds to.\n",
        "    \"\"\"\n",
        "    return {\n",
        "        r.id: get_embedding(r.content) for idx, r in df.iterrows()\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "na9kN64sUvJ3"
      },
      "outputs": [],
      "source": [
        "def load_embeddings(fname: str):\n",
        "    \"\"\"\n",
        "    Read the document embeddings and their keys from a CSV.\n",
        "\n",
        "    fname is the path to a CSV with exactly these named columns:\n",
        "        \"title\", \"heading\", \"0\", \"1\", ... up to the length of the embedding vectors.\n",
        "    \"\"\"\n",
        "\n",
        "    df = pd.read_csv(fname, header=0)\n",
        "    max_dim = max([int(c) for c in df.columns if c != \"title\" and c != \"heading\"])\n",
        "    return {\n",
        "           (r.title, r.heading): [r[str(i)] for i in range(max_dim + 1)] for _, r in df.iterrows()\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TuwhIlZ6XeyI"
      },
      "outputs": [],
      "source": [
        "def vector_similarity(x , y ) :\n",
        "    \"\"\"\n",
        "    Returns the similarity between two vectors.\n",
        "\n",
        "    Because OpenAI Embeddings are normalized to length 1, the cosine similarity is the same as the dot product.\n",
        "    \"\"\"\n",
        "    return np.dot(np.array(x), np.array(y))\n",
        "\n",
        "def order_document_sections_by_query_similarity(query , contexts ) :\n",
        "    \"\"\"\n",
        "    Find the query embedding for the supplied query, and compare it against all of the pre-calculated document embeddings\n",
        "    to find the most relevant sections.\n",
        "\n",
        "    Return the list of document sections, sorted by relevance in descending order.\n",
        "    \"\"\"\n",
        "    query_embedding = get_embedding(query)\n",
        "\n",
        "    document_similarities = sorted([\n",
        "        (vector_similarity(query_embedding, doc_embedding), doc_index) for doc_index, doc_embedding in contexts.items()\n",
        "    ], reverse=True)\n",
        "\n",
        "    return document_similarities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y8XioqfzrtHZ"
      },
      "outputs": [],
      "source": [
        "def retrieve(question: str, context_embeddings: dict, df: pd.DataFrame) -> str:\n",
        "    \"\"\"\n",
        "    Fetch most 10 similar passages to a question\n",
        "    \"\"\"\n",
        "    most_relevant_document_sections = order_document_sections_by_query_similarity(question, context_embeddings)\n",
        "    chosen_sections = []\n",
        "    scores = []\n",
        "    chosen_sections_len = 0\n",
        "    chosen_sections_indexes = []\n",
        "\n",
        "    i = 0\n",
        "    for score, section_index in most_relevant_document_sections:\n",
        "        # Add contexts until we run out of space.\n",
        "        # document_section = df.loc[int(section_index)]\n",
        "\n",
        "        i = i + 1\n",
        "        if i > 10:\n",
        "            break\n",
        "\n",
        "        # chosen_sections.append(SEPARATOR + document_section.content.replace(\"\\n\", \" \"))\n",
        "        chosen_sections_indexes.append(section_index)\n",
        "        scores.append(score)\n",
        "\n",
        "    return chosen_sections_indexes, scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fb7k0AWDU9CQ"
      },
      "outputs": [],
      "source": [
        "# calculate the encodings for the passages\n",
        "document_embeddings = compute_doc_embeddings(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uJ6121MdsrL6"
      },
      "outputs": [],
      "source": [
        "dataset_name = 'QQA23_TaskA_dev.tsv'\n",
        "with open(dataset_name, 'r') as f:\n",
        "    text = f.read()\n",
        "\n",
        "paragraphs = []\n",
        "current_paragraph = \"\"\n",
        "sentences = text.split('\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ByMpmEBdvQDJ"
      },
      "outputs": [],
      "source": [
        "ids = []\n",
        "questions = []\n",
        "result = []\n",
        "for sentence in sentences:\n",
        "    words = sentence.split(\"\\t\")\n",
        "    if(len(words) == 2):\n",
        "      retreived, scores = retrieve(words[1],document_embeddings,\n",
        "    df)\n",
        "      if len(scores) == 0:\n",
        "        result.append([words[0], \"Q0\", -1, 1, 1, 'Abdul'])\n",
        "      else:\n",
        "        if scores[0] < threshold:\n",
        "          result.append([words[0], \"Q0\", -1, 1, 1, 'Abdul'])\n",
        "        else:\n",
        "          for i in range(len(retreived)):\n",
        "            if(scores[i] < threshold):\n",
        "              break\n",
        "            result.append([words[0], \"Q0\", retreived[i], i + 1, scores[i], 'Abdul'])\n",
        "df_run = pd.DataFrame(result, columns=['qid', 'Q0', 'docno', 'rank', 'score', 'tag'])\n",
        "df_run[[\"qid\", \"Q0\", \"docno\", \"rank\", \"score\", \"tag\"]].to_csv('AlJawaab_emb.tsv', sep=\"\\t\", index=False, header=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0EY6KY3UyKzf"
      },
      "outputs": [],
      "source": [
        "# evaluation dev or training datasets\n",
        "! python QQA23_TaskA_eval.py \\\n",
        "    -r \"AlJawaab_emb.tsv\" \\\n",
        "    -q \"GOLD_ANSWERS_FILE.gold\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E63n1lUYrEfx"
      },
      "outputs": [],
      "source": [
        "# checking the test answers file\n",
        "! python QQA23_TaskA_submission_checker.py \\\n",
        "    --model-prediction \\\n",
        "    \"AlJawaab_emb.tsv\"\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}