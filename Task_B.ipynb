{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade openai\n",
        "!pip install arabic-reshaper\n",
        "!pip install pyarabic\n",
        "!pip install tiktoken\n",
        "!pip install farasapy"
      ],
      "metadata": {
        "id": "fTWhjXbw8mG8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List\n",
        "import numpy as np\n",
        "import openai\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import tiktoken\n",
        "import json\n",
        "import time\n",
        "import re\n"
      ],
      "metadata": {
        "id": "uuEnR3Y4ctE3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kNEkKRFca33Q"
      },
      "outputs": [],
      "source": [
        "\n",
        "COMPLETIONS_MODEL = \"gpt-4\"\n",
        "# COMPLETIONS_MODEL = \"gpt-3.5-turbo\"\n",
        "openai.api_key = 'YOUT_OPENAI_API_KEY'\n",
        "dataset_file = \"QQA23_TaskB_qrcd_v1.2_test_preprocessed.jsonl\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CMMRFM2ca33T"
      },
      "outputs": [],
      "source": [
        "def load_jsonl(input_path) -> list:\n",
        "    data = []\n",
        "    with open(input_path, 'r', encoding='utf-8') as f:\n",
        "        for line in f:\n",
        "            data.append(json.loads(line.rstrip('\\n|\\r')))\n",
        "    print('Loaded {} records from {}'.format(len(data), input_path))\n",
        "    return data\n",
        "\n",
        "\n",
        "def get_last_token_index(text):\n",
        "    tokens = text.split()  # Split the string into tokens\n",
        "    if tokens:\n",
        "        last_token_index = len(tokens) - 1 # Get the last token index\n",
        "        return last_token_index\n",
        "    else:\n",
        "        return -1  # Return -1 if the string has no tokens\n",
        "\n",
        "\n",
        "def to_dict(answer, rank, score, start_token_indx, end_token_indx):\n",
        "    return {\n",
        "        # \"pq_id\": pq_id,\n",
        "        \"answer\": answer,\n",
        "        \"strt_token_indx\":start_token_indx,\n",
        "        \"end_token_indx\":end_token_indx,\n",
        "        \"rank\":rank,\n",
        "        \"score\":score,\n",
        "        }\n",
        "\n",
        "\n",
        "def form_one_answer(passage):\n",
        "    answers_list = []\n",
        "    answers_list.append(to_dict(answer=passage, rank=1, score=1, start_token_indx=0, end_token_indx=get_last_token_index(passage)))\n",
        "    return answers_list\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_phrase_index(text, phrase):\n",
        "    words = text.split()\n",
        "    phrase_words = phrase.split()\n",
        "    for i in range(len(words) - len(phrase_words) + 1):\n",
        "        if words[i:i + len(phrase_words)] == phrase_words:\n",
        "            return i  # Return the index of the first word in the phrase\n",
        "\n",
        "    return -1"
      ],
      "metadata": {
        "id": "A0gUlJ-klChD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def form_answers(passage, answers):\n",
        "    answers = answers.replace('\"', '')  # Remove double quotation marks\n",
        "    answers = answers.replace(\"'\", '')  # Remove single quotation marks\n",
        "    answers_list = []\n",
        "    answers = answers.split(\"\\n\")\n",
        "    i = 1\n",
        "    for answer in answers:\n",
        "      if('no answer' in answer.lower()):\n",
        "        break\n",
        "      words = answer.split(\" \")\n",
        "      if(len(words) == 0):\n",
        "        continue\n",
        "      if(len(words) >= 2):\n",
        "        start_token_indx = get_phrase_index(passage, \" \".join(words[0:2]))\n",
        "        if start_token_indx == -1:\n",
        "          continue\n",
        "      else:\n",
        "        if words[0] in passage:\n",
        "          passage_words = passage.split(\" \")\n",
        "          start_token_indx = passage_words.index(words[0])\n",
        "        else:\n",
        "          continue\n",
        "\n",
        "      end_token_indx = start_token_indx + len(words) - 1\n",
        "      answers_list.append(to_dict(answer=answer, rank=i, score=1, start_token_indx=start_token_indx, end_token_indx=end_token_indx))\n",
        "      i = i + 1\n",
        "      if i > 10:\n",
        "        break\n",
        "    return answers_list"
      ],
      "metadata": {
        "id": "GHNCj4RcpEY6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "24vbgvRxa33l",
        "outputId": "e4b2f817-06dd-411d-a8ae-886ad389de9b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 431 records from QQA23_TaskB_qrcd_v1.2_test_preprocessed.jsonl\n"
          ]
        }
      ],
      "source": [
        "dataset_jsonl  = load_jsonl(dataset_file)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "COMPLETIONS_API_PARAMS = {\n",
        "    # We use temperature of 0.0 because it gives the most predictable, factual answer.\n",
        "    \"temperature\": 0.0,\n",
        "    \"max_tokens\": 1000,\n",
        "    \"model\": COMPLETIONS_MODEL,\n",
        "}"
      ],
      "metadata": {
        "id": "IhY5kIpAc_Iz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def answer_question(\n",
        "    question: str,\n",
        "    passage: str,\n",
        "    show_prompt: bool = False,\n",
        ") -> str:\n",
        "\n",
        "    prompt = \"\"\"أجب على السؤال التالي من النص المرفق فقط . لا تقم بإضافة أية شرح أو أية إجابة من خارج النص. اكتب الإجابة أو الإجابات فقط, إن وجدت أكثر من إجابة اكتبها على شكل تعدادات. الاجابة يجب أن تكون فقط المقطع أو المقاطع التي تحوي الجواب بدون أية زيادة. اجعل كل مقطع في سطر منفصل. إن لم توجد إجابة، اكتب: \"No Answer\"\n",
        ".\"\\n\\n\"\"\" + question + \"\\n\" + passage\n",
        "\n",
        "    if show_prompt:\n",
        "        print(prompt)\n",
        "\n",
        "    response = openai.ChatCompletion.create(\n",
        "                messages=[\n",
        "                    {\"role\": \"system\", \"content\" : \"أنت عالم في اللغة العربية وعلوم القرآن\"},\n",
        "                    {\"role\": \"user\", \"content\" : prompt}],\n",
        "                **COMPLETIONS_API_PARAMS\n",
        "            )\n",
        "\n",
        "    return response[\"choices\"][0][\"message\"][\"content\"]"
      ],
      "metadata": {
        "id": "AckiabtFdCtc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TzmFy8fea33n"
      },
      "outputs": [],
      "source": [
        "all_questions = {}\n",
        "answer = ''\n",
        "answers = []\n",
        "i = 0\n",
        "for pq_dict in dataset_jsonl:\n",
        "    pq_id = pq_dict['pq_id']\n",
        "    passage = pq_dict['passage']\n",
        "    question = pq_dict['question']\n",
        "    i = i + 1\n",
        "    if i % 90 == 0:\n",
        "      # wait for half a minute each 90 iteration in order to exceed the tokens per minute limit\n",
        "      time.sleep(30)\n",
        "    try:\n",
        "      answer = answer_question(question, passage, False)\n",
        "    except:\n",
        "      # exception could happen when exceeding the tokens per minute limit, so we try to get the answer again after waiting half a minute\n",
        "      try:\n",
        "        time.sleep(30)\n",
        "        answer = answer_question(question, passage, False)\n",
        "      except:\n",
        "        print(\"error in \", pq_id)\n",
        "        answer = 'error'\n",
        "    answers.append(answer)\n",
        "    answers_list = form_answers(passage, answer)\n",
        "    all_questions.update({pq_id: answers_list})"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_string(input_string):\n",
        "    # Remove symbols using regex\n",
        "    cleaned_string = re.sub(r'[^\\w\\s]', '', input_string)\n",
        "    # Remove leading and trailing whitespaces\n",
        "    cleaned_string = cleaned_string.strip()\n",
        "    return cleaned_string"
      ],
      "metadata": {
        "id": "CXF1WWX7jfK3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# preprocessing the answers\n",
        "all_questions_proc = {}\n",
        "errors = []\n",
        "i = 0\n",
        "for pq_dict in dataset_jsonl:\n",
        "    pq_id = pq_dict['pq_id']\n",
        "    passage = pq_dict['passage']\n",
        "    question = pq_dict['question']\n",
        "\n",
        "    answer = answers[i]\n",
        "\n",
        "    answers_list = form_answers(passage, clean_string(answer))\n",
        "    if answers_list == -2:\n",
        "      errors.append(i)\n",
        "    else:\n",
        "      all_questions_proc.update({pq_id: answers_list})\n",
        "    i = i + 1"
      ],
      "metadata": {
        "id": "IraQoSzKjBOR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# saving the answers in the required format to a json file\n",
        "save_path = \"AlJawaab_gpt4.json\"\n",
        "with open(save_path, \"w\", encoding=\"utf-8\") as outfile:\n",
        "    json.dump(all_questions, outfile, ensure_ascii=False)\n",
        "    print(\"Json file was saved into this path: \",save_path )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Asjw9OsgTHkP",
        "outputId": "50a58a4d-8cf5-4917-d13c-15cf2e60691a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Json file was saved into this path:  abdul_tpgp4.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "txBGloeZBJnB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# saving the processed answers in the required format to a json file\n",
        "save_path = \"AlJawaab_pgpt4.json\"\n",
        "with open(save_path, \"w\", encoding=\"utf-8\") as outfile:\n",
        "    json.dump(all_questions_proc, outfile, ensure_ascii=False)\n",
        "    print(\"Json file was saved into this path: \",save_path )"
      ],
      "metadata": {
        "id": "uNycz5jQBJuV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Saving the original answers to a json file\n",
        "save_path = \"answers_gpt4.json\"\n",
        "with open(save_path, \"w\", encoding=\"utf-8\") as outfile:\n",
        "    json.dump(answers, outfile, ensure_ascii=False)\n",
        "    print(\"Json file was saved into this path: \",save_path )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aMae3dL0e4U5",
        "outputId": "d0395b47-7e9a-4528-aa34-a72935808b7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Json file was saved into this path:  answers_ptest.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluating dev or training dataset\n",
        "! python QQA23_TaskB_eval.py \\\n",
        "    --run_file \"FILE_NAME.jsonl\" \\\n",
        "    --gold_answers_file \"GOLDEN_ANSWER_FILE.jsonl\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P7RwDqsB022W",
        "outputId": "360f55d0-411c-4b44-de91-9c9f2eca1eea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2023-08-22 16:00:52,540 - farasapy_logger - WARNING]: Be careful with large lines as they may break on interactive mode. You may switch to Standalone mode for such cases.\n",
            "Loaded 163 records from QQA23_TaskB_qrcd_v1.2_dev_preprocessed.jsonl\n",
            "pAP@10 = 0.470 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# run submission checker for test dataset\n",
        "! python QQA23_TaskB_submission_checker.py \\\n",
        "    --run_file \"TEST_FILE_NAME.json\"\n",
        "# expected output:\n",
        "# Loaded 163 records from ../QQA23_TaskB_qrcd_v1.2_dev_preprocessed.jsonl\n",
        "# pAP@10 = 25.484\n"
      ],
      "metadata": {
        "id": "lR5PRkRS3O7x"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "b9889cefe40c55d576844f1d6183148761d17be597acfcdddc3fa949f430f6d7"
    },
    "kernelspec": {
      "display_name": "Python 3.7.9 ('venv': venv)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}